# üéØ YOLO Training Setup - Quick Summary

## ‚úÖ Files Created

All files have been created in the `backend/` directory:

### 1. Core Training Files
- **`train_yolo.py`** - Main training script with YOLOv8
- **`prepare_dataset.py`** - Dataset download and conversion to YOLO format
- **`yolo_detector.py`** - YOLO inference and integration class

### 2. Configuration Files
- **`requirements_yolo.txt`** - All Python dependencies for YOLO training
- **`quickstart_yolo.bat`** - Windows quick start script

### 3. Documentation
- **`YOLO_TRAINING_GUIDE.md`** - Complete step-by-step training guide
- **`YOLO_SETUP_SUMMARY.md`** - This file

---

## üöÄ Quick Start (3 Steps)

### Step 1: Install Dependencies
```bash
cd backend

# Create virtual environment
python -m venv venv_yolo

# Activate (Windows)
.\venv_yolo\Scripts\activate

# Install requirements
pip install -r requirements_yolo.txt

# Install PyTorch with CUDA (for GPU)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Step 2: Get Dataset

**Option A: Automatic (Kaggle API)**
```bash
# Setup Kaggle API (one-time)
# 1. Go to kaggle.com/account
# 2. Create API token
# 3. Place kaggle.json in ~/.kaggle/

# Download and prepare
python prepare_dataset.py
# Select option 1 for CBIS-DDSM
```

**Option B: Manual**
```bash
# 1. Download from: https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset
# 2. Extract to: datasets/raw/cbis-ddsm
# 3. Run: python prepare_dataset.py (select option 1)
```

**Option C: Use Your Own Dataset**
```bash
python prepare_dataset.py
# Select option 3
# Then place your images and labels in:
#   datasets/breast_cancer/images/train/
#   datasets/breast_cancer/images/val/
#   datasets/breast_cancer/labels/train/
#   datasets/breast_cancer/labels/val/
```

### Step 3: Train Model
```bash
# Start training
python train_yolo.py

# Training will run and save model to:
# runs/detect/breast_cancer_detector/weights/best.pt
```

---

## üìä What Each Script Does

### `train_yolo.py`
- Loads YOLOv8 pretrained model
- Trains on breast cancer dataset
- Saves best model weights
- Generates training metrics and plots
- Exports to ONNX format

**Output**:
- `runs/detect/breast_cancer_detector/weights/best.pt` - Best model
- `runs/detect/breast_cancer_detector/results.png` - Training curves
- `runs/detect/breast_cancer_detector/confusion_matrix.png` - Performance

### `prepare_dataset.py`
- Downloads dataset from Kaggle (optional)
- Converts annotations to YOLO format
- Splits into train/val/test sets
- Creates dataset.yaml configuration

**Output**:
- `datasets/breast_cancer/` - Organized dataset
- `datasets/breast_cancer/dataset.yaml` - YOLO config

### `yolo_detector.py`
- Loads trained YOLO model
- Runs inference on new images
- Detects cancer types and locations
- Creates visualizations
- Generates structured findings

**Usage**:
```python
from yolo_detector import YOLOCancerDetector

detector = YOLOCancerDetector('models/breast_cancer_yolo.pt')
detections = detector.detect(image)
vis_image = detector.visualize_detections(image, detections)
```

---

## üéì Recommended Kaggle Datasets

### 1. CBIS-DDSM (Recommended for Beginners)
- **Link**: https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset
- **Size**: 2,620 studies
- **Classes**: Mass, Calcification
- **Format**: DICOM with ROI coordinates
- **Best for**: Learning, prototyping

### 2. VinDr-Mammo (Advanced)
- **Link**: https://www.kaggle.com/competitions/vinbigdata-chest-xray-abnormalities-detection
- **Size**: 20,000+ images
- **Classes**: 5 finding categories
- **Format**: Digital mammograms, CSV annotations
- **Best for**: Production-quality models

### 3. INbreast (High Quality)
- **Link**: http://medicalresearch.inescporto.pt/breastresearch/
- **Size**: 410 images (115 cases)
- **Classes**: Multiple lesion types
- **Format**: High-resolution DICOM
- **Best for**: Research, validation

---

## ‚öôÔ∏è Training Configuration

Edit these in `train_yolo.py`:

```python
# Model Selection
MODEL_SIZE = "yolov8n"  # Fast (good for testing)
MODEL_SIZE = "yolov8s"  # Balanced
MODEL_SIZE = "yolov8m"  # Better accuracy
MODEL_SIZE = "yolov8l"  # High accuracy
MODEL_SIZE = "yolov8x"  # Best (slow)

# Training Parameters
EPOCHS = 100            # Training iterations
IMG_SIZE = 640          # Image resolution
BATCH_SIZE = 16         # Images per batch (adjust for GPU memory)

# Dataset Path
DATASET_PATH = "datasets/breast_cancer"
```

---

## üñ•Ô∏è Hardware Requirements

### Minimum (CPU Training)
- CPU: 4+ cores
- RAM: 8GB
- Storage: 20GB
- **Time**: ~2-3 days for 100 epochs

### Recommended (GPU Training)
- GPU: NVIDIA RTX 3060 (8GB VRAM)
- RAM: 16GB
- Storage: 50GB
- **Time**: ~2-4 hours for 100 epochs

### Optimal (Fast Training)
- GPU: NVIDIA RTX 4090 (24GB VRAM)
- RAM: 32GB
- Storage: 100GB
- **Time**: ~1-2 hours for 100 epochs

---

## üîÑ Integration with Existing Backend

After training, integrate YOLO with your backend:

### Step 1: Copy Model
```bash
mkdir -p models
cp runs/detect/breast_cancer_detector/weights/best.pt models/breast_cancer_yolo.pt
```

### Step 2: Update `main.py`
```python
from yolo_detector import YOLOCancerDetector

# Initialize YOLO
yolo_detector = YOLOCancerDetector(
    model_path="models/breast_cancer_yolo.pt",
    confidence_threshold=0.25
)

# In /predict endpoint:
detections = yolo_detector.detect(original_image)
findings = yolo_detector.generate_findings(detections, confidence)
bbox_image = yolo_detector.visualize_detections(original_image, detections)
```

### Step 3: Restart Backend
```bash
cd backend
.\venv\Scripts\python.exe -m uvicorn main:app --reload --host 127.0.0.1 --port 8001
```

---

## üìà Expected Results

After 100 epochs on CBIS-DDSM:

| Metric          | YOLOv8n | YOLOv8s | YOLOv8m | YOLOv8l |
|-----------------|---------|---------|---------|---------|
| **mAP50**       | 0.65    | 0.72    | 0.78    | 0.82    |
| **mAP50-95**    | 0.42    | 0.49    | 0.55    | 0.60    |
| **Precision**   | 0.68    | 0.74    | 0.79    | 0.83    |
| **Recall**      | 0.62    | 0.69    | 0.74    | 0.78    |
| **Inference**   | 120 FPS | 90 FPS  | 60 FPS  | 40 FPS  |

---

## üêõ Common Issues & Solutions

### Issue 1: "CUDA out of memory"
```python
# Solution: Reduce batch size in train_yolo.py
BATCH_SIZE = 8  # or 4
IMG_SIZE = 416  # instead of 640
```

### Issue 2: "Kaggle API not found"
```bash
# Solution: Install and configure
pip install kaggle
# Then place kaggle.json in ~/.kaggle/
```

### Issue 3: "No module named 'ultralytics'"
```bash
# Solution: Install requirements
pip install -r requirements_yolo.txt
```

### Issue 4: Poor detection results
**Solutions**:
1. Train longer (increase EPOCHS)
2. Use larger model (yolov8m or yolov8l)
3. Add more training data
4. Adjust confidence threshold
5. Review dataset quality

---

## üìö Additional Resources

- **Complete Guide**: Read `YOLO_TRAINING_GUIDE.md` for detailed instructions
- **YOLOv8 Docs**: https://docs.ultralytics.com/
- **Dataset Papers**: 
  - CBIS-DDSM: https://www.nature.com/articles/sdata2017177
  - VinDr-Mammo: https://physionet.org/content/vindr-mammo/
- **Support**: Open issue on GitHub or contact team

---

## ‚ö†Ô∏è Important Notes

1. **Medical Use**: This is for research/education only. NOT for clinical diagnosis.
2. **GPU Recommended**: Training on CPU is very slow (days vs hours)
3. **Dataset Size**: More data = better results. Minimum 1000+ images recommended.
4. **Validation**: Always validate model with radiologists before deployment.
5. **Ethics**: Follow medical AI ethics guidelines and regulations.

---

## üéØ Next Steps

1. ‚úÖ **Setup**: Run `quickstart_yolo.bat` or follow manual steps
2. ‚úÖ **Dataset**: Download CBIS-DDSM or prepare your own
3. ‚úÖ **Train**: Run `python train_yolo.py`
4. ‚úÖ **Evaluate**: Check metrics in `runs/detect/`
5. ‚úÖ **Test**: Test on new images
6. ‚úÖ **Integrate**: Update backend to use YOLO
7. ‚úÖ **Deploy**: Deploy trained model

---

**Ready to start training? Follow the Quick Start guide above! üöÄ**

For detailed instructions, see `YOLO_TRAINING_GUIDE.md`

**Questions?** Check the troubleshooting section or refer to documentation.

---

**Good luck with your training! üí™üéØ‚ú®**

